# ğŸ¥‹ Sumo News Emailer

An AI-powered Python application that scrapes news from multiple sumo wrestling sources and converts them into bite-sized, tweet-like email summaries.

## Features

- ğŸ“° **Multi-Source Scraping**: Automatically fetches news from multiple sumo sources:
  - Japan Sumo Association (sumo.or.jp)  
  - Japan Times Sumo Section
  - International Federation of Sumo (IFS)
- ğŸ¤– **AI Processing**: Uses OpenAI to create engaging, tweet-like summaries (under 280 characters)
- âœ‰ï¸ **Email Digest**: Sends formatted HTML and text emails with news summaries
- ğŸ¯ **Smart Filtering**: Filters relevant news, removes duplicates, and shows source attribution
- ğŸ›¡ï¸ **Rate Limiting**: Respectful scraping with built-in delays between sources
- ğŸ”„ **Fallback Support**: Works with or without OpenAI API key (uses basic summaries as fallback)
- ğŸ“Š **SQLite Database**: Tracks all scraped articles, prevents duplicates, maintains processing history

## Project Structure

```
sumo_updates/
â”œâ”€â”€ main.py                 # Main entry point - run this file
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                    # Your environment variables
â”œâ”€â”€ src/                    # Core application code
â”‚   â”œâ”€â”€ main.py            # Application logic
â”‚   â”œâ”€â”€ scraper.py         # News scraping functionality
â”‚   â”œâ”€â”€ emailer.py         # Email sending functionality
â”‚   â”œâ”€â”€ ai_processor.py    # AI/OpenAI integration
â”‚   â””â”€â”€ database.py        # SQLite database operations
â”œâ”€â”€ config/                # Configuration files
â”‚   â””â”€â”€ .env.example       # Environment template
â”œâ”€â”€ data/                  # Data storage
â”‚   â””â”€â”€ sumo_news.db       # SQLite database
â”œâ”€â”€ scripts/               # Automation scripts
â”‚   â”œâ”€â”€ run_sumo_news.bat  # Windows batch runner
â”‚   â””â”€â”€ setup_task_scheduler.ps1  # Task Scheduler setup
â”œâ”€â”€ tests/                 # Test and utility scripts
â”‚   â”œâ”€â”€ test_*.py          # Test files
â”‚   â”œâ”€â”€ manage_db.py       # Database management
â”‚   â””â”€â”€ view_archives.py   # Archive viewer
â”œâ”€â”€ docs/                  # Documentation
â”‚   â”œâ”€â”€ TASK_SCHEDULER_SETUP.md
â”‚   â””â”€â”€ EXAMPLE_EMAIL.md
â”œâ”€â”€ assets/                # Static assets
â”‚   â””â”€â”€ images/            # Email header images
â”œâ”€â”€ logs/                  # Application logs (auto-created)
â””â”€â”€ archives/              # Email archives (auto-created)
```

## Setup

1. **Clone and install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Configure environment variables**:
   ```bash
   cp config/.env.example .env
   # Edit .env with your credentials
   ```

3. **Required environment variables**:
   - `OPENAI_API_KEY`: Your OpenAI API key
   - `EMAIL_HOST`: SMTP server (e.g., smtp.gmail.com)
   - `EMAIL_PORT`: SMTP port (e.g., 587)
   - `EMAIL_USER`: Your email address
   - `EMAIL_PASS`: Your email password/app password
   - `EMAIL_TO`: Recipient email address

## Usage

**Run the main application** (from project root):
```bash
python main.py
```

**Test all components**:
```bash
python main.py --test
```

**Get help**:
```bash
python main.py --help
```

**Alternative: Run from src directory** (legacy):
```bash
cd src && python main.py
```

## Testing

**Quick scraping test (no setup required)**:
```bash
python test_scraping.py
```

**Test all components**:
```bash
python src/main.py --test
```

## Database Management

**View database statistics**:
```bash
python manage_db.py stats
```

**View recent articles**:
```bash
python manage_db.py recent
```

**View unprocessed articles**:
```bash
python manage_db.py unprocessed
```

**Clean up old articles** (removes articles older than 30 days):
```bash
python manage_db.py cleanup
```

## Example Output

**Generate a sample email**:
```bash
python generate_example.py
```

This creates an example email digest showing the format and content style. See [EXAMPLE_EMAIL.md](EXAMPLE_EMAIL.md) for a full sample output.

**Sample email features:**
- Custom pixel art header image ("SUMO UPDATES NEWSLETTER")
- Professional orange-themed HTML design
- Tweet-like AI summaries (under 280 characters)
- Source attribution for each article
- Unsubscribe information and privacy compliance
- Mobile-responsive layout with embedded images

## How It Works

1. **Multi-Source Scraping**: Fetches news from multiple sumo wrestling websites
2. **Database Storage**: Saves all articles to SQLite database with duplicate prevention
3. **Content Analysis**: Extracts relevant sumo news using keyword filtering and deduplication
4. **Source Attribution**: Labels each news item with its source for transparency
5. **AI Processing**: Creates concise, engaging summaries using OpenAI (or basic summaries as fallback)
6. **Email Generation**: Formats news into an attractive HTML/text email digest
7. **Processing Tracking**: Marks articles as processed to avoid re-sending
8. **Delivery**: Sends the digest to your specified email address

## Email Configuration

### Gmail Setup
1. Enable 2-factor authentication on your Gmail account
2. Generate an "App Password" for this application
3. Use your Gmail address as `EMAIL_USER` and the app password as `EMAIL_PASS`

### Other Email Providers
- **Outlook**: Use `smtp-mail.outlook.com`, port 587
- **Yahoo**: Use `smtp.mail.yahoo.com`, port 587
- **Custom SMTP**: Use your provider's SMTP settings

## Sample Output

The application generates emails with:
- **Subject**: AI-generated engaging subject line
- **Introduction**: Brief intro paragraph
- **News Items**: Tweet-like summaries with links to full articles
- **Timestamps**: When articles were published and processed

## Automation

You can schedule this application to run daily using:

**Windows Task Scheduler**:
```cmd
schtasks /create /tn "SumoNews" /tr "python C:\path\to\src\main.py" /sc daily /st 09:00
```

**Linux/Mac Cron**:
```bash
# Add to crontab (runs daily at 9 AM)
0 9 * * * cd /path/to/sumo_updates && python src/main.py
```

## Troubleshooting

- **No news found**: The scraper looks for specific keywords. Check if the website structure changed.
- **Email errors**: Verify SMTP settings and app passwords
- **AI errors**: Confirm your OpenAI API key is valid and has credits
- **Rate limiting**: The app includes delays between requests to be respectful

## Dependencies

- `requests`: HTTP requests for web scraping
- `beautifulsoup4`: HTML parsing and manipulation
- `openai`: AI text processing
- `python-dotenv`: Environment variable management
- `smtplib` & `email`: Built-in email sending functionality